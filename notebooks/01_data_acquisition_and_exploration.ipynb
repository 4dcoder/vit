{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Import configurations\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DATA_ROOT, TACO_ANNOTATION_PATH, TACO_IMAGES_DIR, \\\n\u001b[1;32m     14\u001b[0m                                    TRASH_ICRA19_ROOT, TRASH_ICRA19_IMAGES_DIR, \\\n\u001b[1;32m     15\u001b[0m                                    TRASH_ICRA19_ANNOTATIONS_DIR, TRASH_ICRA19_CLASS_NAMES_PATH, \\\n\u001b[1;32m     16\u001b[0m                                    TRASH_ICRA19_CLASSES, TACO_TO_ICRA19_CLASS_MAP\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Import parsers\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_parsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_taco_annotations, parse_trash_icra19_annotations\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "# notebooks/01_data_acquisition_and_exploration.ipynb\n",
    "# This notebook will guide you through downloading and initial exploration.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Import configurations\n",
    "from config.dataset_config import DATA_ROOT, TACO_ANNOTATION_PATH, TACO_IMAGES_DIR, \\\n",
    "                                   TRASH_ICRA19_ROOT, TRASH_ICRA19_IMAGES_DIR, \\\n",
    "                                   TRASH_ICRA19_ANNOTATIONS_DIR, TRASH_ICRA19_CLASS_NAMES_PATH, \\\n",
    "                                   TRASH_ICRA19_CLASSES, TACO_TO_ICRA19_CLASS_MAP\n",
    "\n",
    "# Import parsers\n",
    "from utils.dataset_parsers import parse_taco_annotations, parse_trash_icra19_annotations\n",
    "\n",
    "print(\"--- 01_data_acquisition_and_exploration.ipynb ---\")\n",
    "print(\"Current Project Root:\", os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n",
    "\n",
    "# --- 1. Dataset Acquisition (Manual Step Guidance) ---\n",
    "\n",
    "# TACO Dataset:\n",
    "print(\"\\n--- TACO Dataset Acquisition ---\")\n",
    "print(\"1. Download TACO annotations (all.json): Go to http://tacodataset.org/ -> Download -> annotations/all.json\")\n",
    "print(f\"   Save it to: {os.path.dirname(TACO_ANNOTATION_PATH)}\")\n",
    "print(\"2. Download TACO images: The images are hosted on Flickr. The TACO dataset website provides a `download.py` script.\")\n",
    "print(\"   Follow instructions on http://tacodataset.org/ to download images. Create a folder named 'images' inside TACO dir.\")\n",
    "print(f\"   Images should be saved to: {TACO_IMAGES_DIR}\")\n",
    "print(\"   Alternatively, you might find pre-packaged TACO datasets on Kaggle or other platforms that include images.\")\n",
    "\n",
    "if not os.path.exists(TACO_ANNOTATION_PATH):\n",
    "    print(f\"WARNING: TACO annotation file not found at {TACO_ANNOTATION_PATH}. Please download it.\")\n",
    "if not os.path.exists(TACO_IMAGES_DIR):\n",
    "    print(f\"WARNING: TACO images directory not found at {TACO_IMAGES_DIR}. Please download images.\")\n",
    "\n",
    "# Trash-ICRA19 Dataset:\n",
    "print(\"\\n--- Trash-ICRA19 Dataset Acquisition ---\")\n",
    "print(\"Assuming 'trash_ICRA19' folder is already in your project root.\")\n",
    "print(f\"Expected path: {TRASH_ICRA19_ROOT}\")\n",
    "print(\"Verify the internal structure matches:\")\n",
    "print(f\"  Images expected in: {TRASH_ICRA19_IMAGES_DIR}\")\n",
    "print(f\"  Annotations expected in: {TRASH_ICRA19_ANNOTATIONS_DIR}\")\n",
    "print(f\"  Class names file expected at: {TRASH_ICRA19_CLASS_NAMES_PATH}\")\n",
    "\n",
    "if not os.path.exists(TRASH_ICRA19_IMAGES_DIR):\n",
    "    print(f\"WARNING: Trash-ICRA19 images directory not found at {TRASH_ICRA19_IMAGES_DIR}.\")\n",
    "if not os.path.exists(TRASH_ICRA19_ANNOTATIONS_DIR):\n",
    "    print(f\"WARNING: Trash-ICRA19 annotations directory not found at {TRASH_ICRA19_ANNOTATIONS_DIR}.\")\n",
    "if not os.path.exists(TRASH_ICRA19_CLASS_NAMES_PATH):\n",
    "    print(f\"WARNING: Trash-ICRA19 classes.txt not found at {TRASH_ICRA19_CLASS_NAMES_PATH}.\")\n",
    "\n",
    "# --- 2. Initial Data Exploration ---\n",
    "\n",
    "print(\"\\n--- Exploring TACO Dataset ---\")\n",
    "taco_raw_data = None\n",
    "if os.path.exists(TACO_ANNOTATION_PATH):\n",
    "    try:\n",
    "        with open(TACO_ANNOTATION_PATH, 'r') as f:\n",
    "            taco_raw_data = json.load(f)\n",
    "        print(f\"Successfully loaded TACO annotations: {len(taco_raw_data['images'])} images, {len(taco_raw_data['annotations'])} annotations.\")\n",
    "\n",
    "        # Display TACO original categories\n",
    "        taco_categories = {cat['id']: cat['name'] for cat in taco_raw_data['categories']}\n",
    "        print(\"\\nTACO Original Categories (first 20):\")\n",
    "        for i, (cat_id, cat_name) in enumerate(taco_categories.items()):\n",
    "            print(f\"- {cat_id}: {cat_name}\")\n",
    "            if i >= 19: break\n",
    "\n",
    "        # Calculate category distribution\n",
    "        taco_cat_counts = defaultdict(int)\n",
    "        for ann in taco_raw_data['annotations']:\n",
    "            taco_cat_counts[taco_categories[ann['category_id']]] += 1\n",
    "\n",
    "        print(\"\\nTACO Category Distribution (Top 10):\")\n",
    "        sorted_taco_cats = sorted(taco_cat_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "        for cat_name, count in sorted_taco_cats[:10]:\n",
    "            print(f\"- {cat_name}: {count} instances\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading/parsing TACO JSON: {e}\")\n",
    "else:\n",
    "    print(\"TACO annotation file not found, skipping detailed exploration.\")\n",
    "\n",
    "print(\"\\n--- Exploring Trash-ICRA19 Dataset ---\")\n",
    "if os.path.exists(TRASH_ICRA19_IMAGES_DIR) and os.path.exists(TRASH_ICRA19_ANNOTATIONS_DIR):\n",
    "    # Using the parser to get structured data\n",
    "    icra19_data_train = parse_trash_icra19_annotations(os.path.join(TRASH_ICRA19_IMAGES_DIR, 'train'),\n",
    "                                                        os.path.join(TRASH_ICRA19_ANNOTATIONS_DIR, 'train'),\n",
    "                                                        TRASH_ICRA19_CLASS_NAMES_PATH)\n",
    "    icra19_data_val = parse_trash_icra19_annotations(os.path.join(TRASH_ICRA19_IMAGES_DIR, 'val'),\n",
    "                                                      os.path.join(TRASH_ICRA19_ANNOTATIONS_DIR, 'val'),\n",
    "                                                      TRASH_ICRA19_CLASS_NAMES_PATH)\n",
    "    icra19_data_test = parse_trash_icra19_annotations(os.path.join(TRASH_ICRA19_IMAGES_DIR, 'test'),\n",
    "                                                       os.path.join(TRASH_ICRA19_ANNOTATIONS_DIR, 'test'),\n",
    "                                                       TRASH_ICRA19_CLASS_NAMES_PATH)\n",
    "\n",
    "    print(f\"Trash-ICRA19 Images: Train={len(icra19_data_train)}, Val={len(icra19_data_val)}, Test={len(icra19_data_test)}\")\n",
    "    print(f\"Trash-ICRA19 Classes: {TRASH_ICRA19_CLASSES}\")\n",
    "\n",
    "    icra19_cat_counts = defaultdict(int)\n",
    "    for data_list in [icra19_data_train, icra19_data_val, icra19_data_test]:\n",
    "        for item in data_list:\n",
    "            for label_id in item['labels']:\n",
    "                for class_name, class_idx in TRASH_ICRA19_CLASSES.items():\n",
    "                    if class_idx == label_id:\n",
    "                        icra19_cat_counts[class_name] += 1\n",
    "                        break\n",
    "    print(\"\\nTrash-ICRA19 Category Distribution:\")\n",
    "    for cat_name, count in icra19_cat_counts.items():\n",
    "        print(f\"- {cat_name}: {count} instances\")\n",
    "\n",
    "    # --- 3. Visualize Sample Images with Annotations ---\n",
    "\n",
    "    def visualize_annotations(image_path, boxes, labels, class_names, title=\"\"):\n",
    "        \"\"\"Displays an image with bounding box annotations.\"\"\"\n",
    "        fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "\n",
    "        for bbox, label_id in zip(boxes, labels):\n",
    "            # Convert [xmin, ymin, w, h] to [xmin, ymin, xmax, ymax] for drawing,\n",
    "            # if the parser provides w,h. If it's xmax,ymax already, no change needed.\n",
    "            # Our parsers convert to [xmin, ymin, w, h]\n",
    "            xmin, ymin, width, height = bbox\n",
    "            xmax, ymax = xmin + width, ymin + height\n",
    "\n",
    "            rect = patches.Rectangle((xmin, ymin), width, height,\n",
    "                                     linewidth=2, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            class_name = class_names.get(label_id, f\"Class {label_id}\") # Get name from ID\n",
    "            plt.text(xmin, ymin - 5, class_name, color='red', fontsize=12,\n",
    "                     bbox=dict(facecolor='white', alpha=0.7, edgecolor='none', pad=0.5))\n",
    "        plt.show()\n",
    "\n",
    "    print(\"\\n--- Visualizing Sample Images (Trash-ICRA19) ---\")\n",
    "    num_samples_to_show = 3\n",
    "    for i, item in enumerate(icra19_data_train[:num_samples_to_show]):\n",
    "        visualize_annotations(item['image_path'], item['boxes'], item['labels'],\n",
    "                              TRASH_ICRA19_CLASSES, title=f\"Trash-ICRA19 Train Sample {i+1}\")\n",
    "\n",
    "    print(\"\\n--- Visualizing Sample Images (TACO - Mapped) ---\")\n",
    "    # For TACO, we need to ensure images are downloaded to `TACO_IMAGES_DIR`\n",
    "    if taco_raw_data and os.path.exists(TACO_IMAGES_DIR) and len(taco_raw_data['images']) > 0:\n",
    "        # Get some random TACO images (with annotations)\n",
    "        taco_parsed = parse_taco_annotations(TACO_ANNOTATION_PATH, TACO_IMAGES_DIR)\n",
    "        random.shuffle(taco_parsed)\n",
    "        for i, item in enumerate(taco_parsed[:num_samples_to_show]):\n",
    "            # The parser returns [xmin, ymin, w, h] for boxes\n",
    "            visualize_annotations(item['image_path'], item['boxes'], item['labels'],\n",
    "                                  TRASH_ICRA19_CLASSES, # Use ICRA19 classes as TACO is mapped\n",
    "                                  title=f\"TACO Sample {i+1} (Mapped to ICRA19)\")\n",
    "            if i >= num_samples_to_show - 1: break\n",
    "    else:\n",
    "        print(\"Skipping TACO visualization: Data or images not found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Trash-ICRA19 dataset not found, skipping detailed exploration.\")\n",
    "\n",
    "print(\"\\n--- Exploration Complete ---\")\n",
    "print(\"Review class distributions and sample images. Pay attention to the domain shift (underwater vs. terrestrial) and annotation quality.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
