{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# notebooks/02_data_preprocessing_and_dataset.ipynb\n",
    "# This notebook will demonstrate the usage of your TrashDetectionDataset and DataLoader.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Import configurations\n",
    "from config.dataset_config import TRASH_ICRA19_CLASSES, TACO_ANNOTATION_PATH, TACO_IMAGES_DIR, \\\n",
    "                                   TRASH_ICRA19_IMAGES_DIR, TRASH_ICRA19_ANNOTATIONS_DIR, \\\n",
    "                                   TRASH_ICRA19_CLASS_NAMES_PATH, NUM_CLASSES_ICRA19\n",
    "\n",
    "# Import custom dataset and collate_fn\n",
    "from datasets.trash_detection_dataset import TrashDetectionDataset, collate_fn\n",
    "\n",
    "# Import the DetectionTransforms from datasets/trash_detection_dataset.py for consistency\n",
    "# For a real project, this would be moved to `utils/data_augmentations.py`\n",
    "# but for now, we'll keep it near the Dataset class to be self-contained for testing.\n",
    "from datasets.trash_detection_dataset import DetectionTransforms # Re-import or define here for clarity\n",
    "\n",
    "print(\"--- 02_data_preprocessing_and_dataset.ipynb ---\")\n",
    "\n",
    "# --- 1. Define Transforms and Augmentations ---\n",
    "# This is where you'll define the robust augmentation strategy.\n",
    "# For now, we'll use a basic transform from `DetectionTransforms`.\n",
    "# Later, you will enhance `utils/data_augmentations.py` with more advanced transforms.\n",
    "\n",
    "# For training, you'd typically have more aggressive augmentations.\n",
    "# For validation/test, usually only resizing and normalization.\n",
    "\n",
    "train_transforms = DetectionTransforms(size=(800, 800)) # Larger size for training\n",
    "val_test_transforms = DetectionTransforms(size=(800, 800)) # Consistent size\n",
    "\n",
    "# --- 2. Instantiate Datasets ---\n",
    "\n",
    "print(\"\\n--- Instantiating Datasets ---\")\n",
    "\n",
    "# TACO Dataset (for primary training)\n",
    "# Note: TACO does not have pre-defined train/val/test splits. You'd typically split it manually\n",
    "# if you want a dedicated TACO validation, or just use it as a large training pool.\n",
    "# For now, we'll load the full mapped dataset as a \"train\" set.\n",
    "taco_train_dataset = TrashDetectionDataset(\n",
    "    dataset_name='taco',\n",
    "    transforms=train_transforms,\n",
    "    taco_json_path=TACO_ANNOTATION_PATH,\n",
    "    taco_images_dir=TACO_IMAGES_DIR\n",
    ")\n",
    "print(f\"TACO training dataset size: {len(taco_train_dataset)} images.\")\n",
    "\n",
    "# Trash-ICRA19 Dataset (for fine-tuning and evaluation)\n",
    "icra19_train_dataset = TrashDetectionDataset(\n",
    "    dataset_name='trash_icra19',\n",
    "    split='train',\n",
    "    transforms=train_transforms,\n",
    "    icra19_images_dir=TRASH_ICRA19_IMAGES_DIR,\n",
    "    icra19_annotations_dir=TRASH_ICRA19_ANNOTATIONS_DIR,\n",
    "    icra19_class_names_path=TRASH_ICRA19_CLASS_NAMES_PATH\n",
    ")\n",
    "print(f\"Trash-ICRA19 training dataset size: {len(icra19_train_dataset)} images.\")\n",
    "\n",
    "icra19_val_dataset = TrashDetectionDataset(\n",
    "    dataset_name='trash_icra19',\n",
    "    split='val',\n",
    "    transforms=val_test_transforms,\n",
    "    icra19_images_dir=TRASH_ICRA19_IMAGES_DIR,\n",
    "    icra19_annotations_dir=TRASH_ICRA19_ANNOTATIONS_DIR,\n",
    "    icra19_class_names_path=TRASH_ICRA19_CLASS_NAMES_PATH\n",
    ")\n",
    "print(f\"Trash-ICRA19 validation dataset size: {len(icra19_val_dataset)} images.\")\n",
    "\n",
    "icra19_test_dataset = TrashDetectionDataset(\n",
    "    dataset_name='trash_icra19',\n",
    "    split='test',\n",
    "    transforms=val_test_transforms,\n",
    "    icra19_images_dir=TRASH_ICRA19_IMAGES_DIR,\n",
    "    icra19_annotations_dir=TRASH_ICRA19_ANNOTATIONS_DIR,\n",
    "    icra19_class_names_path=TRASH_ICRA19_CLASS_NAMES_PATH\n",
    ")\n",
    "print(f\"Trash-ICRA19 test dataset size: {len(icra19_test_dataset)} images.\")\n",
    "\n",
    "\n",
    "# --- 3. Create DataLoaders ---\n",
    "\n",
    "print(\"\\n--- Creating DataLoaders ---\")\n",
    "\n",
    "BATCH_SIZE = 2 # Small batch size for demonstration\n",
    "NUM_WORKERS = 0 # Set to >0 for faster loading in production, but 0 for debugging in notebooks\n",
    "\n",
    "taco_train_loader = DataLoader(taco_train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                               num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "icra19_train_loader = DataLoader(icra19_train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                 num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "icra19_val_loader = DataLoader(icra19_val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                               num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "icra19_test_loader = DataLoader(icra19_test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                                num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "\n",
    "print(\"DataLoaders created. Ready to iterate through batches.\")\n",
    "\n",
    "# --- 4. Iterate and Verify a Batch ---\n",
    "\n",
    "print(\"\\n--- Verifying Batches ---\")\n",
    "\n",
    "# Verify TACO Batch\n",
    "print(\"\\n--- Sample Batch from TACO Training Loader ---\")\n",
    "for batch_idx, (images, targets) in enumerate(taco_train_loader):\n",
    "    print(f\"Batch {batch_idx+1}:\")\n",
    "    print(f\"  Images batch shape: {images.shape}\") # Should be [BATCH_SIZE, 3, H, W]\n",
    "    print(f\"  Number of targets in batch: {len(targets)}\") # Should be BATCH_SIZE\n",
    "    for i, target in enumerate(targets):\n",
    "        print(f\"    Target {i+1}:\")\n",
    "        print(f\"      Boxes (normalized cxcywh): {target['boxes'].shape} {target['boxes'].dtype}\")\n",
    "        print(f\"      Labels: {target['labels'].shape} {target['labels'].dtype} -> {target['labels'].tolist()}\")\n",
    "        print(f\"      Image ID: {target['image_id'].item()}\")\n",
    "        print(f\"      Area: {target['area'].shape}\")\n",
    "        print(f\"      iscrowd: {target['iscrowd'].shape}\")\n",
    "        print(f\"      Original Size: {target['orig_size'].tolist()}\") # Original H, W\n",
    "        print(f\"      Current Size: {target['size'].tolist()}\") # Resized H, W\n",
    "\n",
    "    # You can visualize a batch if needed (denormalize images, convert boxes back)\n",
    "    if batch_idx == 0:\n",
    "        # Denormalize image for visualization\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "        def show_image_with_boxes(img_tensor, boxes_cxcywh_norm, labels, title=\"\"):\n",
    "            img = img_tensor * std + mean # Denormalize\n",
    "            img = T.ToPILImage()(img)\n",
    "\n",
    "            fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(title)\n",
    "            ax.axis('off')\n",
    "\n",
    "            img_width, img_height = img.size\n",
    "            for bbox_norm, label_id in zip(boxes_cxcywh_norm, labels):\n",
    "                # Convert normalized cxcywh to absolute xmin, ymin, xmax, ymax\n",
    "                cx, cy, w, h = bbox_norm.tolist()\n",
    "                xmin = (cx - w / 2) * img_width\n",
    "                ymin = (cy - h / 2) * img_height\n",
    "                xmax = (cx + w / 2) * img_width\n",
    "                ymax = (cy + h / 2) * img_height\n",
    "\n",
    "                rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                         linewidth=2, edgecolor='r', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                class_name = list(TRASH_ICRA19_CLASSES.keys())[label_id]\n",
    "                plt.text(xmin, ymin - 5, class_name, color='red', fontsize=12,\n",
    "                         bbox=dict(facecolor='white', alpha=0.7, edgecolor='none', pad=0.5))\n",
    "            plt.show()\n",
    "\n",
    "        # Show the first image from the batch\n",
    "        if len(images) > 0 and len(targets[0]['boxes']) > 0:\n",
    "            show_image_with_boxes(images[0], targets[0]['boxes'], targets[0]['labels'],\n",
    "                                  title=\"TACO Sample with Transformed Annotations\")\n",
    "        else:\n",
    "            print(\"No bounding boxes found in first TACO batch for visualization.\")\n",
    "    break # Only show first batch for TACO\n",
    "\n",
    "# Verify Trash-ICRA19 Batch\n",
    "print(\"\\n--- Sample Batch from Trash-ICRA19 Validation Loader ---\")\n",
    "for batch_idx, (images, targets) in enumerate(icra19_val_loader):\n",
    "    print(f\"Batch {batch_idx+1}:\")\n",
    "    print(f\"  Images batch shape: {images.shape}\")\n",
    "    print(f\"  Number of targets in batch: {len(targets)}\")\n",
    "    for i, target in enumerate(targets):\n",
    "        print(f\"    Target {i+1}:\")\n",
    "        print(f\"      Boxes (normalized cxcywh): {target['boxes'].shape} {target['boxes'].dtype}\")\n",
    "        print(f\"      Labels: {target['labels'].shape} {target['labels'].dtype} -> {target['labels'].tolist()}\")\n",
    "        print(f\"      Image ID: {target['image_id'].item()}\")\n",
    "        print(f\"      Area: {target['area'].shape}\")\n",
    "        print(f\"      iscrowd: {target['iscrowd'].shape}\")\n",
    "        print(f\"      Original Size: {target['orig_size'].tolist()}\")\n",
    "        print(f\"      Current Size: {target['size'].tolist()}\")\n",
    "\n",
    "    if batch_idx == 0:\n",
    "        if len(images) > 0 and len(targets[0]['boxes']) > 0:\n",
    "            show_image_with_boxes(images[0], targets[0]['boxes'], targets[0]['labels'],\n",
    "                                  title=\"Trash-ICRA19 Val Sample with Transformed Annotations\")\n",
    "        else:\n",
    "            print(\"No bounding boxes found in first Trash-ICRA19 batch for visualization.\")\n",
    "    break # Only show first batch for ICRA19\n",
    "\n",
    "print(\"\\n--- Preprocessing and Dataset Setup Complete for Phase 1 ---\")\n",
    "print(\"You are now ready to proceed to Phase 2: ViT Object Detection Training & Evaluation.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
